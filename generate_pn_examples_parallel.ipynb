{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0dd7276da505e97266161a797b95775da2a9bf2bc5ab82b43772a2fec0db2adf7",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "dd7276da505e97266161a797b95775da2a9bf2bc5ab82b43772a2fec0db2adf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_process.self_supervised.batch_loader_v2 as batch_loader\n",
    "import data_process.self_supervised.data_reader as data_reader\n",
    "import data_process.self_supervised.label_generator as label_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Data Processing : 100%|██████████| 82819/82819 [03:51<00:00, 358.31it/s]\n",
      "Label Generation : 100%|██████████| 82819/82819 [01:29<00:00, 928.19it/s]\n",
      "Collecting Training Info : 100%|██████████| 82819/82819 [00:00<00:00, 289978.92it/s]\n",
      "Computing Node Info : 100%|██████████| 82819/82819 [01:34<00:00, 875.07it/s]\n"
     ]
    }
   ],
   "source": [
    "path = \"../train_80k\"\n",
    "dr = data_reader.Data_Reader(path)\n",
    "lg = label_generator.LabelGenerator(dr)\n",
    "bl = batch_loader.Batch_Loader_V2(dr, lg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch_pn_indices(itr_range):\n",
    "        \n",
    "        multi_pn = []\n",
    "        for mask_index in itr_range:\n",
    "            # declare the list to contain a positve subtree id and negative_sample_size neagtive subtree ids\n",
    "            pn_list = []\n",
    "            pn_list.append(bl.subtree_index[mask_index]) # add the positve subtree id at index 0\n",
    "\n",
    "            # create the removal list\n",
    "            which_label = bl.tree_mask_index[mask_index]\n",
    "            label = bl.label_generator.labels[which_label]\n",
    "            removal_list = bl.get_unique_label(label)\n",
    "            \n",
    "            # create negative subtree id list\n",
    "            pn_list.extend(bl.select_negative_samples(removal_list))\n",
    "\n",
    "            # append to dataset\n",
    "            multi_pn.append(pn_list)\n",
    "        return multi_pn\n",
    "\n",
    "# import pickle\n",
    "\n",
    "# with open('../batch_loader_v2/batch_loader_100k_test.pkl', 'wb') as file:\n",
    "#     pickle.dump(bl, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[range(0, 68298), range(68298, 136596), range(136596, 204894), range(204894, 273192), range(273192, 341490), range(341490, 409788), range(409788, 478086), range(478086, 546384), range(546384, 614682), range(614682, 682980), range(682980, 751278), range(751278, 819576), range(819576, 887874), range(887874, 956172), range(956172, 1024470), range(1024470, 1092768), range(1092768, 1161066), range(1161066, 1229364), range(1229364, 1297662), range(1297662, 1365960), range(1365960, 1434258), range(1434258, 1502556), range(1502556, 1570854), range(1570854, 1639152), range(1639152, 1707450), range(1707450, 1775723)]\n",
      "1775723\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import math\n",
    "if mp.cpu_count() > 2:\n",
    "    # parallel process, greater than 2 because always reserve one core for other system usages\n",
    "    num_cores = mp.cpu_count() - 2\n",
    "    pool = mp.Pool(num_cores)\n",
    "\n",
    "    # create the list of iterables\n",
    "    itrs = []\n",
    "    division = math.ceil(bl.num_train / num_cores)\n",
    "    \n",
    "    for i in range(num_cores):\n",
    "        start = i * division\n",
    "        end = start + division if start + division < bl.num_train else bl.num_train\n",
    "        itrs.append(range(start, end))\n",
    "        if (end == bl.num_train):\n",
    "            break\n",
    "    \n",
    "    print(itrs)\n",
    "\n",
    "    res = pool.map(get_batch_pn_indices, [itr_range for itr_range in itrs])\n",
    "\n",
    "    for lis in res:\n",
    "        bl.batch_pn_indices.extend(lis)\n",
    "    print(len(bl.batch_pn_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "with open('../batch_loader_v2/batch_loader_80k_5neg.pkl', 'wb') as file:\n",
    "    pickle.dump(bl, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 13873/13873 [11:09<00:00, 20.72it/s]\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "num_batches = math.ceil(bl.num_train/batch_size)\n",
    "for idx in tqdm(range(num_batches)):\n",
    "    bl.retrieve_batch(idx, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}