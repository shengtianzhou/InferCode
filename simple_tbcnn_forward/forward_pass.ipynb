{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emulate a forward pass given a complete binary tree of depth 2 (in total, 3 nodes)\n",
    "# token of 3\n",
    "# type vocabulary of 3\n",
    "# hyper parameter dimension\n",
    "token_size = 3\n",
    "type_size = 3\n",
    "dim = 2\n",
    "\n",
    "# create the type embedding and vocabulary embedding\n",
    "token_embed = nn.Embedding(token_size, dim)\n",
    "type_embed = nn.Embedding(type_size, dim)\n",
    "\n",
    "# create a linear layer to extract node embedding from the token and type embeddings\n",
    "linear = nn.Linear(dim*2, dim)\n",
    "\n",
    "zero_tensor = torch.zeros(dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the input tree representation\n",
    "# for each node, there needs to be (type_id, token_id)\n",
    "tree_with_indices = torch.tensor([[[0,0],[1,1],[2,2]],[[1,1],[-1,-1],[-1,-1]],[[2,2],[-1,-1],[-1,-1]]])\n",
    "# convert tree_with_indices to tree with vectors based on type and token embedding\n",
    "def embed(tree):\n",
    "    embed_tree = []\n",
    "    for subtree_nodes in tree:\n",
    "        subtree_embed = []\n",
    "        for type_index, token_index in subtree_nodes:\n",
    "            node_embed = []\n",
    "            if type_index != -1:\n",
    "                concat = torch.cat((type_embed(type_index), token_embed(token_index)), 0) \n",
    "                node_embed = [linear(concat).tolist()]\n",
    "                #print(node_embed)\n",
    "            else:\n",
    "                node_embed = [zero_tensor.tolist()]\n",
    "                #print(node_embed)\n",
    "            subtree_embed.append(node_embed)\n",
    "        embed_tree.append(subtree_embed)\n",
    "    return torch.tensor(embed_tree).squeeze(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([3, 3, 2])\ntensor([[[ 0.4627, -1.1416],\n         [ 0.2623, -0.0223],\n         [ 0.7116, -1.8547]],\n\n        [[ 0.2623, -0.0223],\n         [ 0.0000,  0.0000],\n         [ 0.0000,  0.0000]],\n\n        [[ 0.7116, -1.8547],\n         [ 0.0000,  0.0000],\n         [ 0.0000,  0.0000]]])\n"
     ]
    }
   ],
   "source": [
    "# derive the embedded tree with type and token information fused through a linear layer\n",
    "tree_embed = embed(tree_with_indices)\n",
    "print(tree_embed.size())\n",
    "print(tree_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the tbcnn method to convolve nodes to a single vector\n",
    "# declare the embedding for top, left, and right node\n",
    "t_emb = nn.Parameter(torch.rand([dim, dim])) \n",
    "r_emb = nn.Parameter(torch.rand([dim, dim]))\n",
    "l_emb = nn.Parameter(torch.rand([dim, dim]))\n",
    "bias = nn.Parameter(torch.rand(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eta_t(di, d):\n",
    "    # di is the height of the node i in the sliding window, starting from 1, not 0. d is the total depth of the tree\n",
    "    return (di - 1.0) / (d - 1.0)\n",
    "\n",
    "def eta_r(etat, pi, n):\n",
    "    # pi is the position of the child node, from left to right, the position should be 1, 2, ..., n\n",
    "    if n == 1:\n",
    "        return 0\n",
    "    return (1.0 - etat) * (pi - 1.0) / (n - 1.0)\n",
    "\n",
    "def eta_l(etat, etar):\n",
    "    return (1.0 - etat) * (1.0 - etar)\n",
    "\n",
    "def convovle(tree_emb):\n",
    "    #incomplete\n",
    "    conv_tree = []\n",
    "    for subtree in tree_emb:\n",
    "        y = 0.0\n",
    "        for node_id, node_vec in enumerate(subtree):\n",
    "            node_vec = node_vec.unsqueeze(1)\n",
    "            if node_id == 0:\n",
    "                # this is the parent node\n",
    "                etat = 1\n",
    "                y = etat * torch.matmul(t_emb,node_vec)\n",
    "            else :\n",
    "                if torch.sum(node_vec) != 0.0:\n",
    "                    etat = 0\n",
    "                    etar = eta_r(etat, node_id, 2)\n",
    "                    etal = eta_l(etat, etar)\n",
    "                    y += etat * torch.matmul(t_emb, node_vec) + etar * torch.matmul(r_emb, node_vec) + etal * torch.matmul(l_emb, node_vec)\n",
    "        y = torch.tanh(y + bias).tolist()\n",
    "        # tolist() is fine for calculating the tbcnn embedding, but not ok when going for gradient decent because torch operation information is lost\n",
    "        conv_tree.append(y)\n",
    "    return torch.tensor(conv_tree).squeeze()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "tbcnn_output = convovle(tree_embed)"
   ]
  }
 ]
}