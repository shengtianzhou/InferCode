{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0dd7276da505e97266161a797b95775da2a9bf2bc5ab82b43772a2fec0db2adf7",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "dd7276da505e97266161a797b95775da2a9bf2bc5ab82b43772a2fec0db2adf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inference.InferCode_Inference as II\n",
    "import data_process.self_supervised.data_reader as data_reader\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import time\n",
    "import tqdm\n",
    "import copy\n",
    "import math\n",
    "\n",
    "token_dict_path = \"/home/stanley/Desktop/dictionaries/token2id.json\"\n",
    "type_dict_path = \"/home/stanley/Desktop/dictionaries/type2id.json\"\n",
    "model_weight_path = \"/home/stanley/Desktop/model_weights/epoch_77.pkl\"\n",
    "subtree_count = 635374\n",
    "dimension = 64\n",
    "\n",
    "inferencer = II.InferCode_Inference(model_weight_path, token_dict_path, type_dict_path, subtree_count, dimension)\n",
    "\n",
    "# code examples to get code vector\n",
    "file_path = \"/home/stanley/Desktop/test_20k\"\n",
    "# file_path = \"/home/stanley/Desktop/test_dataset_100k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# construct a tree that has 10% smaller number of nodes\n",
    "def reduce(tree, percentage):\n",
    "    reduced_tree = copy.deepcopy(tree)\n",
    "    node_count = len(reduced_tree.getroot().findall(\".//*\"))\n",
    "    threshold = math.ceil(node_count * percentage)\n",
    "    delete_e = []\n",
    "    difference = node_count\n",
    "\n",
    "    for e in reduced_tree.iter():\n",
    "        num_child = len(e.findall(\".//*\"))\n",
    "        if abs(num_child - threshold) < difference :\n",
    "            delete_e = e\n",
    "            difference = abs(num_child - threshold)\n",
    "    delete_e.clear()\n",
    "    delete_e.tag = \"unknown_type\"\n",
    "    delete_e.text = \"unknown_token\"\n",
    "\n",
    "    #return 1.0 - len(reduced_tree.getroot().findall(\".//*\"))/node_count\n",
    "    return reduced_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Data Processing : 100%|██████████| 20705/20705 [00:50<00:00, 409.01it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = data_reader.Data_Reader(file_path).processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_file_paths(path):\n",
    "        '''\n",
    "        collect individual xml file path and return those as a list\n",
    "        '''\n",
    "        file_paths = []\n",
    "        for root, directories, filenames in os.walk(path):\n",
    "            for filename in filenames:\n",
    "                file_paths.append(os.path.join(root,filename))\n",
    "        return file_paths\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_direct = \"/home/stanley/Desktop/model_weights\"\n",
    "model_paths = collect_file_paths(model_direct)\n",
    "paths = collect_file_paths(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "20705it [02:22, 144.85it/s]\n"
     ]
    }
   ],
   "source": [
    "full_tree = []\n",
    "tree_10 = []\n",
    "tree_30 = []\n",
    "\n",
    "len_full = []\n",
    "len_10 = []\n",
    "len_30 = []\n",
    "\n",
    "for idx, path in tqdm.tqdm(enumerate(paths)):\n",
    "    original_tree = ET.parse(path)\n",
    "    full_tree.append(copy.deepcopy(original_tree))\n",
    "    tree_10.append(reduce(original_tree, 0.1))\n",
    "    tree_30.append(reduce(original_tree, 0.3))\n",
    "    len_full.append(len(original_tree.getroot().findall(\".//*\")))\n",
    "    len_10.append(len(tree_10[idx].getroot().findall(\".//*\")))\n",
    "    len_30.append(len(tree_30[idx].getroot().findall(\".//*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1it [00:00, 253.48it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "Could not infer dtype of NoneType",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-2bf4d0f9a2d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mcode_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferencer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_tree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mcode_vector_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferencer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_10\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/InferCode/inference/InferCode_Inference.py\u001b[0m in \u001b[0;36mcode2vec\u001b[0;34m(self, file_path, tree)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;31m# code vector production\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;31m# convert batched data to torch tensor with the appropriate dtype, and put them on the gpu assume gpu is available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mbatch_window_tree_node_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_of_windowed_tree_node_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0mbatch_window_tree_node_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_of_windowed_tree_node_tokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mbatch_window_tree_node_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_of_windowed_tree_node_indices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Could not infer dtype of NoneType"
     ]
    }
   ],
   "source": [
    "for model_path in model_paths:\n",
    "    inferencer = II.InferCode_Inference(model_path, token_dict_path, type_dict_path, subtree_count, dimension)\n",
    "\n",
    "    positive_count = 0\n",
    "    total = len(paths)\n",
    "    difference = 0.1 # 10%\n",
    "\n",
    "    for idx, path in tqdm.tqdm(enumerate(paths)):\n",
    "        \n",
    "        if len_10[idx]/len_full[idx] - len_30[idx]/len_full[idx] < difference: # remove examples that have a small difference in removed nummber of nodes\n",
    "\n",
    "            total -= 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            code_vector = inferencer.code2vec(copy.deepcopy(full_tree[idx]), tree = True)\n",
    "\n",
    "            code_vector_10 = inferencer.code2vec(copy.deepcopy(tree_10[idx]), tree = True)\n",
    "\n",
    "            code_vector_30 = inferencer.code2vec(copy.deepcopy(tree_30[idx]), tree = True)\n",
    "            \n",
    "            if np.linalg.norm(code_vector-code_vector_10) < np.linalg.norm(code_vector-code_vector_30):\n",
    "                positive_count += 1\n",
    "        \n",
    "    print(model_path, \" has accuracy :\", positive_count / total, \" The total number is \", total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}