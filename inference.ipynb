{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0dd7276da505e97266161a797b95775da2a9bf2bc5ab82b43772a2fec0db2adf7",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "dd7276da505e97266161a797b95775da2a9bf2bc5ab82b43772a2fec0db2adf7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inference.InferCode_Inference as II\n",
    "import data_process.self_supervised.data_reader as data_reader\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import time\n",
    "import tqdm\n",
    "import copy\n",
    "import math\n",
    "\n",
    "token_dict_path = \"/home/stanley/Desktop/dictionaries/v2_dic/token2id.json\"\n",
    "type_dict_path = \"/home/stanley/Desktop/dictionaries/v2_dic/type2id.json\"\n",
    "subtree_count = 633916 # 633916 for the SS-PTM v2\n",
    "dimension = 64\n",
    "\n",
    "# code examples to get code vector\n",
    "file_path = \"/home/stanley/Desktop/test_20k\"\n",
    "# file_path = \"/home/stanley/Desktop/test_dataset_100k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "distance between function 1 and 2 0.11583154\ndistance between function 1 and 3 0.2632058\ndistance between function 2 and 3 0.19725583\n"
     ]
    }
   ],
   "source": [
    "# test the bubblesort algorithm\n",
    "model2 = II.InferCode_Inference(\"/home/stanley/Desktop/momentum_model_weight/epoch_2.pkl\", token_dict_path, type_dict_path, subtree_count, dimension)\n",
    "bsort1 = \"/home/stanley/Desktop/code1.xml\"\n",
    "bsort2 = \"/home/stanley/Desktop/code2.xml\"\n",
    "bsort3 = \"/home/stanley/Desktop/code3.xml\"\n",
    "\n",
    "def distance(vec1, vec2):\n",
    "    return np.linalg.norm(vec1-vec2)\n",
    "\n",
    "def cos(x, y):\n",
    "    return np.dot(x,y) / (np.sqrt(np.dot(x,x)) * np.sqrt(np.dot(y,y)))\n",
    "\n",
    "vec_1 = model2.code2vec(bsort1)\n",
    "vec_2 = model2.code2vec(bsort2)\n",
    "vec_3 = model2.code2vec(bsort3)\n",
    "\n",
    "d12 = distance(vec_1, vec_2)\n",
    "d13 = distance(vec_1, vec_3)\n",
    "d23 = distance(vec_2, vec_3)\n",
    "\n",
    "print(\"distance between function 1 and 2\", d12)\n",
    "print(\"distance between function 1 and 3\", d13)\n",
    "print(\"distance between function 2 and 3\", d23)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# construct a tree that has 'percentage(e.g., 0.1 or 10%)' less number of nodes\n",
    "def reduce(tree, percentage):\n",
    "    reduced_tree = copy.deepcopy(tree)\n",
    "    node_count = len(reduced_tree.getroot().findall(\".//*\"))\n",
    "    threshold = math.ceil(node_count * percentage)\n",
    "    delete_e = []\n",
    "    difference = node_count\n",
    "\n",
    "    for e in reduced_tree.iter():\n",
    "        num_child = len(e.findall(\".//*\"))\n",
    "        if abs(num_child - threshold) < difference :\n",
    "            delete_e = e\n",
    "            difference = abs(num_child - threshold)\n",
    "    delete_e.clear()\n",
    "    delete_e.tag = \"unknown_type\"\n",
    "    delete_e.text = \"unknown_token\"\n",
    "\n",
    "    #return 1.0 - len(reduced_tree.getroot().findall(\".//*\"))/node_count\n",
    "    return reduced_tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Data Processing : 100%|██████████| 20705/20705 [00:57<00:00, 357.71it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = data_reader.Data_Reader(file_path).processed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_file_paths(path):\n",
    "        '''\n",
    "        collect individual xml file path and return those as a list\n",
    "        '''\n",
    "        file_paths = []\n",
    "        for root, directories, filenames in os.walk(path):\n",
    "            for filename in filenames:\n",
    "                file_paths.append(os.path.join(root,filename))\n",
    "        return file_paths\n",
    "\n",
    "def get_node_count(tree):\n",
    "    return len(tree.getroot().findall(\".//*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "20705it [02:34, 133.59it/s]\n"
     ]
    }
   ],
   "source": [
    "paths = collect_file_paths(file_path)\n",
    "full_tree = []\n",
    "tree_10 = []\n",
    "tree_30 = []\n",
    "\n",
    "len_full = [] # the number of nodes for each original tree\n",
    "len_10 = [] # the number of nodes for each tree with 10% less nodes\n",
    "len_30 = [] # the number of nodes for each tree with 30% less nodes\n",
    "\n",
    "for idx, path in tqdm.tqdm(enumerate(paths)):\n",
    "    original_tree = ET.parse(path)\n",
    "    full_tree.append(copy.deepcopy(original_tree))\n",
    "    tree_10.append(reduce(original_tree, 0.1))\n",
    "    tree_30.append(reduce(original_tree, 0.3))\n",
    "    len_full.append(get_node_count(original_tree))\n",
    "    len_10.append(len(tree_10[idx].getroot().findall(\".//*\")))\n",
    "    len_30.append(len(tree_30[idx].getroot().findall(\".//*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "899it [00:21, 42.28it/s]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-d44e32ea45cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mcode_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferencer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfull_tree\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mcode_vector_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferencer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_10\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mcode_vector_30\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferencer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree_30\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/InferCode/inference/InferCode_Inference.py\u001b[0m in \u001b[0;36mcode2vec\u001b[0;34m(self, file_path, tree)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# tree based convolution, n * dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m         \u001b[0mconvoluted_node_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_convoluted_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_window_tree_node_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_eta_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_eta_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_eta_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;31m# code vector generation, T * dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/InferCode/inference/InferCode_Inference.py\u001b[0m in \u001b[0;36mget_convoluted_result\u001b[0;34m(self, hidden_state, node_indices, eta_t, eta_l, eta_r)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;31m# add them together, N * dim * dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m         \u001b[0madded_conv_tlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv_t\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mconv_l\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mconv_r\u001b[0m \u001b[0;31m# N * dim * dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# for the batch of windowed tree nodes, get its convoluted result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_direct = \"/home/stanley/Desktop/one_model\"\n",
    "model_paths = collect_file_paths(model_direct)\n",
    "for model_path in model_paths:\n",
    "    inferencer = II.InferCode_Inference(model_path, token_dict_path, type_dict_path, subtree_count, dimension)\n",
    "\n",
    "    positive_count = 0\n",
    "    total = len(paths)\n",
    "    difference_threshold = 0.1 # 10%\n",
    "    negative_count = 0\n",
    "    total_diff = 0\n",
    "    for idx, path in tqdm.tqdm(enumerate(paths)):\n",
    "        \n",
    "        difference = len_10[idx]/len_full[idx] - len_30[idx]/len_full[idx]\n",
    "\n",
    "        if difference < difference_threshold: # remove examples that have a small difference in removed nummber of nodes\n",
    "\n",
    "            total -= 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            code_vector = inferencer.code2vec(copy.deepcopy(full_tree[idx]), tree = True)\n",
    "\n",
    "            code_vector_10 = inferencer.code2vec(copy.deepcopy(tree_10[idx]), tree = True)\n",
    "\n",
    "            code_vector_30 = inferencer.code2vec(copy.deepcopy(tree_30[idx]), tree = True)\n",
    "            \n",
    "            # if cos(code_vector, code_vector_10) > cos(code_vector, code_vector_30):\n",
    "            if np.linalg.norm(code_vector-code_vector_10) < np.linalg.norm(code_vector-code_vector_30):\n",
    "                positive_count += 1\n",
    "            else:\n",
    "                # for the negative ones, calculate the average distance\n",
    "                negative_count += 1\n",
    "                total_diff += difference\n",
    "    print(model_path, \" has accuracy :\", positive_count / total, \" The total number is \", total)\n",
    "    print(\"average difference for negative pairs\", total_diff/negative_count)\n",
    "    # SS-PTM-v1 with momentum, epoch 59, accuracy: 88%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}